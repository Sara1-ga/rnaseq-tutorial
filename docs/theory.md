# RNAseq Analysis

Before we dive into the nf-core pipeline used for the analysis of RNA-sequencing data, it's worth looking at some theoretical aspects of RNA-seq.

## Overview

Given the central role of the RNA in a variety of cellular and molecular functions, nowadays, RNA-seq became one of the most powerful and important approaches to measure the presence and the levels of RNA species in biological samples. The technique is based on next generation sequencing (NGS) technologies, and it is now considered as the gold standard in the transcriptomic field.

After RNA extraction and reverse transcription into complementary DNA (cDNA), the biological material is sequenced with the generation of NGS “reads”, sequences corresponding to the RNA captured and sequenced in a specific cell, tissue or organ at a given time. Sequencing data are then bioinformatically processed with a typical workflow summarized in the diagram below:

![overview](./img/RNA_seq_scheme_tutorial.png)

In the scheme we can identify three different key phases in the workflow: pre-processing, alignment (or pseudoalignment) and quantification and finally differential expression analysis. In the pre-processing step, the raw reads are handled to remove adapters and contaminants and the quality is checked. Then, reads are mapped to a genome reference and the abundance of transcripts or genes is estimated. The workflow can also follow an additional route based on a pseudoalignment and quantification, reducing the amount of time required for the analysis. Finally, differentially expressed genes or transcripts are identified with statistical tests, annotated and visualized. Depending upon the user’s needs, the workflow can include additional downstream analysis such as functional enrichment analysis (to identify enriched biological pathways or processes), coexpression analysis (to identify hub genes and their relationships) and integration with other omics data (to produce a comprehensive understanding of biological systems).

## Pre-processing 

The pre-processing of sequencing reads from RNA-seq data is a critical step to ensure the quality and accuracy of downstream analysis. The raw reads obtained from the sequencer are stored as [FASTQ] files (https://en.wikipedia.org/wiki/FASTQ_format). The starting data were initially processed to evaluate the quality and identify potential issues such as sequencing errors, adapter contamination or low-quality bases. Reads with low-quality bases or overall poor sequencing quality are removed.
Then, the presence of adapters (short DNA sequences ligated to the ends of DNA fragments during library preparation) is tested through the comparison of each read to a set of known adapter sequences or by using algorithms that detect adapter-like sequences and removed in a process known as “read trimming”. Finally, reads containing contaminants (genomic DNA and/or rRNA) are filtered out and the quality of filtered reads was checked again to ensure their suitability to undergo the downstream processing. 

## Alignment (or pseudoalignment) and quantification

In the RNA-seq workflow, the alignment step refers to the process of mapping sequencing reads to a reference genome or transcriptome with the goal of determining the position and orientation of each read relative to the reference sequence and allowing the subsequent gene expression quantification.

Errors, gaps or poor sequence quality regions as well as insertions/deletions (INDELs), duplicated and repetitive regions make this step challenging. Addressing these issues during the alignment step, by choosing a high-quality reference and an appropriate aligner, is essential for obtaining accurate and reliable results. A crucial component in the RNA-seq workflow is the [annotation](https://www.ncbi.nlm.nih.gov/genbank/genomes_gff) file, either in form of General Feature Format file (GFF) or in form of Gene Transfer Format file (GTF). These file formats contain key information about the location and structure of genes and transcripts and are essential for both mapping sequencing reads accurately during the alignment step and to quantify genes expression in the quantification step. Additionally, RNA-seq data often include reads that span exon-exon junctions and the annotation files provide information about splice junctions allowing the inference of different isoforms.

The aligment and quantification steps can follow two different steps according to user preferences:
- alignment and quantification;
- pseudoalignment and quantification.
In the context of RNA-seq analysis the alignmnet phase is often performed with splice-aware aligners that are utilized to take in account the splicing process. In addition to aligning reads across known splice junctions, splice-aware aligners also aim to detect novel splice junctions and alternative splicing events. Splice-aware aligners are optimized for speed and memory efficiency to handle the large volumes of RNA-seq data generated in modern sequencing experiments. They employ sophisticated algorithms and various optimization techniques, such as indexing the reference genome, parallel processing and memory-mapping, to achieve fast and scalable alignment. Popular splice-aware aligners include [STAR](https://github.com/alexdobin/STAR) and [HISAT2](https://github.com/DaehwanKimLab/hisat2). The following step is typically the quantification, which involves estimating the abundance of genes or transcripts in the samples. The workflow involves the generation of a index from the reference genome and the annotation file (GFF/GTF). This index will be used by the quantification software to map aligned reads to annotated transcripts and quantify their expression levels. The resulting expression counts or abundance estimates represent the number of reads assigned to each transcript in the samples. Several tools are available to perform the quantification step such as [featureCounts](https://subread.sourceforge.net/featureCounts.html), [HTSeq](https://htseq.readthedocs.io), [Salmon](http://combine-lab.github.io/salmon) and [RSEM](http://deweylab.github.io/RSEM).
The alignment and the quantification steps can be also performed with lightweight alignment tools, which include [Kallisto](https://pachterlab.github.io/kallisto/about.html), [Sailfish](http://www.cs.cmu.edu/~ckingsf/software/sailfish) and Salmon. These tools avoid a base-to-base alignment of reads providing quantification estimates faster than the classical splice-aware algorithms but with a high accuracy. The resulting estimates are commonly referred to as “pseudocounts” or “abundance estimates”, that can be later utilized for downstream analysis.
An example showing the differences between a reference-based aligner (STAR) and a pseudoaligner (Salmon) are represented in the scheme below:



In the sketch we can see two typical examples of alignment/pseudoalignemnt and quantification performed with two classical software, STAR and Salmon:

1) STAR seed finding process begins by searching the longest continuos portions of the reads that exactly match to one location of the reference genome (Maximal Mappable Prefix, MMP). The fragments of the reads that mapped separately are defined "seeds". If the reads comprise a splice junction (as shown in the example), the first seed will be mapped to a donor splice site. The MMP search is then applied to the unmapped portion of the read, that will be mapped to an acceptor splice site. The MMP search allows read alignment also in case of mismatches and indels, utilizing the MMP as anchor for the extension. If the extension procedure results in a poor genomic alignment (presence of library adapters or poor sequencing quality tails), the read is soft clipped. In the next step, the "anchor" alignments are selected and all the alignments located within a user-defined genomic window around the anchors are stitched together in order to find the best "linear" alignemnt. STAR assigns scores to each alignment based on various factors, including the number of mismatches, the presence of splice junctions and the overall quality alignment. The stiched combination with the highest score will result in the best alignment of a read. Through this stiching procedure also reads with a large number of mismatches, indels and gaps can be aligned. Finally, gene expression levels can be quantified with different quantification tools like the ones cited above;

2) Salmon starts by constructing a index of the transcriptome. The indexing process combines the use of a suffix array for efficient substring matching and alignment, and a hash table for rapid retrieval of transcript-specific information based on k-mer sequences. Salmon concatenates all transcripts into a single long string representing the entire transcriptome where each transcript is separated by a unique delimiter ($). Salmon generates all possible suffixes of the concatenated string and sort them lexicographically enabling efficient substring matching and search operations. 
The software also extracts all possible k-mers (fixed-length substring of nucleotides) from the transcriptome. Salmon employs a hash function to convert each k-mer sequence into a numerical hash value. The hash function maps k-mer sequences to indices within the hash table. Salmon extracts k-mers also from the read sequences and performs a lookup in the hash table for each extracted k-mer. By querying the hash table, the software retrieves the transcript position(s) within the suffix array and searches the suffix array to identify the transcript(s) that contain the k-mer sequence(s). Once Salmon identifies the candidate transcript(s) based on the matches found in the suffix array, it quantifies the abundance of each transcript. Finally the tools 


## Differential expression (DE) analysis

The next step in a typical RNA-seq workflow is the differential expression analysis. It is a statistical method to compare gene expression levels between different experimental conditions such disease vs healthy (tumor tissue vs healthy tissue), treatment vs control (sample treated with a specific stimulus, drug or compound vs untreated sample), tissue vs tissue (brain vs heart). This part of the analysis in typically performed in R utilizing different packages such as [DESeq2] (https://bioconductor.org/packages/release/bioc/html/DESeq2.html), [edgeR](https://bioconductor.org/packages/release/bioc/html/edgeR.html) and [limma](https://bioconductor.org/packages/release/bioc/html/limma.html). This tutorial is based on the use of DESeq2.
Before getting into details, it is important to point some common characteristics of RNA-seq data that are essential in the choiche of the statistical model to utilize:





Differential expression analysis is composed by different key steps:

- the analysis starts with a matrix obtained in the alignment and quantification step that summarizes the expression levels of the different genes in each sample of the dataset. The rows of the matrix typically correspond to genes and the columns represent the samples. Each position of the matrix contains an integer value representing the number of reads associated to a particular gene in a specific sample. Another essential prerequisite is a metadata table describing the experimental conditions and replicates

