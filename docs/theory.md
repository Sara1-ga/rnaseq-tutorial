# RNAseq Analysis

Before we dive into the nf-core pipeline used for the analysis of RNA-sequencing data, it's worth looking at some theoretical aspects of RNA-seq.

## Overview

Given the central role of RNA in a variety of cellular and molecular functions, RNA-seq has emerged as a powerful tool to measure the presence and levels of RNA species in biological samples. The technique is based on next-generation sequencing (NGS) technologies and is now considered the gold standard in the transcriptomic field.

After RNA extraction and reverse transcription into complementary DNA (cDNA), the biological material is sequenced, generating NGS "reads" that correspond to the RNA captured in a specific cell, tissue, or organ at a given time. The sequencing data are then bioinformatically processed through a typical workflow summarized in the diagram below:

![overview](./img/Excalidraw_RNAseq.png)

In the scheme, we can identify three different key phases in the workflow: data preprocessing, alignment and quantification, and differential expression analysis. In the data preprocessing step, the raw reads are handled to remove adapters and contaminants, and their quality is checked. Then, reads are mapped to a reference genome and the gene abundance is estimated. The workflow can also follow an additional route based on lightweight alignment and quantification, reducing the amount of time required for the analysis. Finally, differentially expressed genes are identified using statistical tests, annotated and visualised. 
Depending on the user's needs, the workflow can include additional downstream analyses such as functional enrichment analysis, coexpression analysis and integration with other omics data.

## Pre-processing 

The pre-processing of sequencing reads from RNA-seq data is a critical step to ensure the quality and accuracy of downstream analysis. The raw reads obtained from the sequencer are stored as [FASTQ](https://en.wikipedia.org/wiki/FASTQ_format) files, which contain both the sequence data and quality scores. The initial processing step involves evaluating the quality of the reads and identifying potential issues such as adapter contamination, sequencing errors or low-quality bases. The presence of adapters (short DNA sequences ligated to the ends of DNA fragments during library preparation) is detected through comparison with known adapter sequences or using algorithms that identify adapter-like sequences, and removed in a process known as **read trimming**. Next, reads containing contaminants (genomic DNA and/or rRNA) and with low-quality bases are filtered out. Finally, the quality of the filtered reads is checked again to ensure their suitability for downstream processing.

## Alignment (or lightweight alignment) and quantification

In the RNA-seq workflow, the alignment step refers to the process of mapping sequencing reads to a reference genome or transcriptome with the goal of determining the position and orientation of each read relative to the reference sequence.

Errors, gaps, or poor sequence quality regions, as well as insertions/deletions (INDELs), duplicated and repetitive regions in the reference sequence make this step challenging. Addressing these issues by choosing a high-quality reference and an appropriate aligner is essential for obtaining accurate results. A crucial component in the alignment step is the [annotation](https://www.ncbi.nlm.nih.gov/genbank/genomes_gff) file, either in form of General Feature Format file (GFF) or in form of Gene Transfer Format file (GTF). These files contain key information about the location and structure of genes and transcripts. For this reason they play a crucial role in both mapping sequencing reads accurately and in quantifying gene expression. Additionally, RNA-seq data often include reads that span exon-exon junctions and the annotation files provide information about splice junctions allowing the inference of different isoforms.

The aligment and quantification steps can follow two different routes according to user preferences:
- alignment and quantification;
- lightweight alignment and quantification.

In the context of RNA-seq analysis, the alignment phase is often performed with splice-aware aligners that are utilised to take into account the splicing process. In addition to align reads across known splice junctions, splice-aware aligners also aim to detect novel splice junctions and alternative splicing events. Splice-aware aligners employ sophisticated algorithms and various optimization techniques, such as indexing the reference genome and parallel processing to achieve fast and scalable alignment. Popular splice-aware aligners include [STAR](https://github.com/alexdobin/STAR) and [HISAT2](https://github.com/DaehwanKimLab/hisat2). The following step is typically the quantification, which involves estimating the abundance (number of reads) assigned to each gene. Several tools are available to perform the quantification step, such as [featureCounts](https://subread.sourceforge.net/featureCounts.html), [HTSeq](https://htseq.readthedocs.io), [Salmon](http://combine-lab.github.io/salmon) and [RSEM](http://deweylab.github.io/RSEM).
The alignment and the quantification steps can be also performed with lightweight alignment tools, which include [Kallisto](https://pachterlab.github.io/kallisto/about.html), [Sailfish](http://www.cs.cmu.edu/~ckingsf/software/sailfish) and Salmon. These tools avoid a base-to-base alignment of reads providing quantification estimates faster than the classical splice-aware algorithms, but with a high accuracy. The resulting estimates are commonly referred to as **pseudocounts** or **abundance estimates**, that can be later utilised for downstream analysis.

## Differential expression (DE) analysis

Tipically, the next step is the differential expression analysis. It is a statistical method to compare gene expression levels between different experimental conditions such disease vs. healthy (e.g., tumor tissue vs. healthy tissue), treatment vs control (e.g., sample treated with a specific stimulus, drug or compound vs untreated sample), tissue vs tissue (e.g., brain vs heart). The objective of differential expression analysis is to assess, for each gene, whether the observed differences in expression between groups are statistically significant, accounting for the variation observed within groups (replicates).
Before delving into details, it is important to point out some common characteristics of RNA-seq data that are essential in the choiche of the statistical model to utilize:

1) **Low Counts and Long Right Tail**: RNA-seq data typically include a large number of genes with low expression counts, reflecting that many genes are expressed at very low levels across samples. At the same time, RNA-seq data show a skewed distribution with a long right tail due to the absence of an upper limit for gene expression levels. This means that while most genes have low to moderate expression levels, a small number of genes are expressed at high levels. Accurate statistical modeling must therefore account for this distribution to avoid misleading conclusions.

   ![overview](./img/count_distribution.png)

2) **Overdispersion**: RNA-seq data are characterised by overdispersion, where the variance in gene expression levels often exceeds the mean (variance > mean). This variability derives from a combination of different factors (biological variations, technical noise, different sequencing depth across samples) and it is higher than expected under a Poisson distribution, which assumes that the mean equals the variance (mean = variance).Effective modeling of RNA-seq data requires statistical methods capable of handling the overdispersion. The negative binomial distribution, which generalizes the Poisson distribution, addresses overdispersion by introducing an additional parameter, the **dispersion** parameter. This parameter quantifies the extra variability present in RNA-seq data, providing a more realistic representation compared to the Poisson distribution. 

   ![overview](./img/overdispersion.png)

To model counts data with robust statistical methods, different software have been developed. This part of the analysis is typically performed in R utilizing packages such as [DESeq2](https://bioconductor.org/packages/release/bioc/html/DESeq2.html), [edgeR](https://bioconductor.org/packages/release/bioc/html/edgeR.html) and [limma](https://bioconductor.org/packages/release/bioc/html/limma.html). This tutorial focuses on **DESeq2**, a popular R package known for its robustness. For more detailed information and details refer to the [DESeq2 vignette](https://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html). The typical workflow is outlined in the flowchart below:

Differential expression analysis is composed by different key steps:

- **Input data**: the analysis starts with a matrix obtained in the alignment and quantification step that summarizes the expression levels of the different genes in each sample of the dataset. The rows of the matrix typically correspond to genes and the columns represent the samples. Another essential prerequisite is a metadata table describing the samples;

- **Normalisation**: since differential expression analysis tools compare counts between sample groups for the same gene, they do not need to account for gene length. However, it is crucial to account for sequencing depth and RNA composition. To normalise data, DESeq2 utilise the size factors, which correct for variations in library sizes and RNA composition across samples. Specifically, DESeq2 calculates size factors (tipically a number around 1) using the **median ratio** method. This involves:
- calculate the geometric mean of each gene's counts across all samples (row-wise geometric mean); 
- divide each gene's count by its geometric mean; 
- take the median of these ratios for each sample (column-wise) to obtain the size factors;
- divide each raw count by its size factor to generate normalised counts.
The median ratio method assumes that not all genes are differentially expressed, so large outlier genes will not negatively influence the median ratio values. This approach is robust to imbalances in up-/down-regulation and can handle large numbers of differentially expressed genes.
Importantly, DESeq2 performs differential expression analysis using raw counts, incorporating the size factor adjustment within the Generalized Linear Model (GLM). 

> [!NOTE] 
> The normalised counts are beneficial for downstream visualization of results, they should not be used as input for DESeq2 or any other differential expression analysis tools that rely on the negative binomial model;

- **Quality Control (QC)**: DESeq2 provides tools for quality control, including Principal Component Analysis (PCA) and hierarchical clustering. PCA is used to reduce the dimensionality of the data, allowing visualization of the samples in a lower-dimensional space. On the other hand, hierarchical clustering displays the correlation of gene expression for all pairwise combinations of samples in the dataset. These methods can reveal group of samples that behave similarly and can highlight potential outliers or unexpected sample patterns. For these quality control steps, DESeq2 typically uses variance-stabilized (vst) counts or regularized log-transformed (rlog) counts. RNA-seq count data follow a discrete distribution which is not suitable for many statistical and machine learning algorithms that assume continuous distributions. These transformations stabilize the variance across the range of mean values. This means that genes with low expression and genes with high expression will have variances that are more comparable to each other after transformation.
Finally, prior to differential expression analysis, it is beneficial to filter out genes that are unlikely to be detected as differentially expressed. This filtering enhances the sensitivity to detect truly differentially expressed genes. These include genes with zero counts across all samples, genes with extreme count outliers, and genes with consistently low mean normalized counts across samples;

- **Differential expression analysis with DESeq2**: the process begins by modeling the raw counts, where normalisation factors (also known as **size factors**) are applied to adjust for differences in library depth and RNA composition between samples. Next, DESeq2 estimates gene-wise dispersions and then shrinks these estimates to produce more accurate and reliable dispersion values, which are used to model the count data. The final steps involve fitting a negative binomial model to the data and performing hypothesis testing using either the Wald test or Likelihood Ratio Test to identify differentially expressed genes.
So we can sum-up the different steps:

. **Estimate the size factors** (normalisation of the raw counts described above);

. **Estimate gene-wise dispersion**: to quantify dispersion DESeq2 utilizes the dispersion parameter (α) is closely tied to the mean (μ) and variance of the data, as described by the equation Var = μ + α * μ^2. This relationship has important implications: for genes with moderate to high count values, the square root of dispersion is equivalent to the coefficient of variation (Var / μ), which represents the relative variability around the mean. A key feature of DESeq2's dispersion estimates is that they are negatively correlated with the mean and positively correlated with variance, resulting in higher dispersion values for genes with low expression levels and lower dispersion values for genes with high expression levels. In addition, genes with the same mean expression levels can exhibit different dispersion estimates based on their variance. To refine these estimates, DESeq2 shares information from genes with similar expression profiles, assuming that they exhibit similar dispersion patterns. By doing so, DESeq2 generates more accurate estimates of variation that are specifically tailored to the mean expression level of each gene;

. **Fit curve to gene-wise dispersion estimates**: this process, known as dispersion fitting, aims to model the relationship between the mean expression level of a gene and its dispersion. By doing so, DESeq2 can identify a trend in the dispersion estimates across genes, which is essential for accurate variance estimation. The fitted curve, typically a smooth curve, describes how dispersion changes as a function of the mean expression level;

. **Shrink gene-wise dispersion estimates**: the gene-wise dispersion estimates are shrunk towards the fitted curve, a process known as shrinkage. By pooling information across genes, DESeq2 can generate more accurate and reliable estimates of dispersion, even for genes with limited sample sizes or noisy data. The shrinkage step adjusts the gene-wise dispersion estimates, moving them closer to the fitted curve, which represents the average dispersion pattern across all genes. This adjustment helps to reduce the variability and noise associated with individual gene-wise estimates, resulting in more robust and consistent dispersion values. However, genes with exceptionally high dispersion values are not shrinked because they probably deviate from the modelling assumption, exhibiting elevated variability due to biological or technical factors. Shrinking these values could lead to false positives. By shrinking the dispersion estimates, DESeq2 can improve the accuracy of downstream analyses and reduce the number of false positives;

. **Generalized Linear Model (GLM), Wald test and multiple test**: DESeq2 fits a generalized linear model (GLM) to the count data for each gene, using a negative binomial distribution to account for overdispersion (variance > mean). The GLM fit is then used to perform hypothesis testing for differential expression using the Wald test. The Wald test is a statistical test that evaluates the significance of the regression coefficients in the GLM, and is used to determine whether the gene is differentially expressed between conditions. However, when performing multiple tests, such as in the case of RNA-seq data where thousands of genes are tested, the risk of false positives increases. To account for this, DESeq2 employs multiple test correction methods (Benjamini-Hochberg procedure is the default) to adjust the p-values and control the false discovery rate (FDR). For example by setting the FDR cutoff to < 0.05, 5% of genes identified as differentially expressed are expected to be false positive. For instance, if 400 genes are identified as differentially expressed with an FDR cutoff of 0.05, you would expect 20 of them to be false positives. This ensures that the results are truly significant and biologically relevant. By combining the GLM, Wald test, and multiple test correction, DESeq2 provides a powerful and accurate approach for identifying differentially expressed genes in RNA-seq data.

After identifying differentially expressed genes using DESeq2, it is essential to interpret the biological significance of these genes through functional analysis. This involves examining the roles of the differentially expressed genes in various biological processes, molecular functions and pathways providing insights into the underlying mechanisms driving the observed changes in gene expression. Different tools are available to carry out these functional analyses such as [Gene Ontology](https://geneontology.org), [Reactome](https://reactome.org/), [KEGG](https://www.genome.jp/kegg), [clusterProfiler](https://bioconductor.org/packages/release/bioc/html/clusterProfiler.html), [g:Profiler](https://biit.cs.ut.ee/gprofiler), and [WikiPathways](https://www.wikipathways.org).