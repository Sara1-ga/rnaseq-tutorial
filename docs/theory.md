# RNAseq Analysis

Before we dive into the nf-core pipeline used for the analysis of RNA-sequencing data, it's worth looking at some theoretical aspects of RNA-seq.

## Overview

Given the central role of the RNA in a variety of cellular and molecular functions, nowadays, RNA-seq became one of the most powerful and important approaches to measure the presence and the levels of RNA species in biological samples. The technique is based on next generation sequencing (NGS) technologies, and it is now considered as the gold standard in the transcriptomic field.

After RNA extraction and reverse transcription into complementary DNA (cDNA), the biological material is sequenced with the generation of NGS “reads”, sequences corresponding to the RNA captured and sequenced in a specific cell, tissue or organ at a given time. Sequencing data are then bioinformatically processed with a typical workflow summarized in the diagram below:

![overview](./img/RNA_seq_scheme_tutorial.png)

In the scheme we can identify three different key phases in the workflow: pre-processing, alignment (or pseudoalignment) and quantification and finally differential expression analysis. In the pre-processing step, the raw reads are handled to remove adapters and contaminants and the quality is checked. Then, reads are mapped to a genome reference and the abundance of transcripts or genes is estimated. The workflow can also follow an additional route based on a pseudoalignment and quantification, reducing the amount of time required for the analysis. Finally, differentially expressed genes or transcripts are identified with statistical tests, annotated and visualized. Depending upon the user’s needs, the workflow can include additional downstream analysis such as functional enrichment analysis (to identify enriched biological pathways or processes), coexpression analysis (to identify hub genes and their relationships) and integration with other omics data (to produce a comprehensive understanding of biological systems).

## Pre-processing 

The pre-processing of sequencing reads from RNA-seq data is a critical step to ensure the quality and accuracy of downstream analysis. The raw reads obtained from the sequencer are stored as [FASTQ] files (https://en.wikipedia.org/wiki/FASTQ_format). The starting data were initially processed to evaluate the quality and identify potential issues such as sequencing errors, adapter contamination or low-quality bases. Reads with low-quality bases or overall poor sequencing quality are removed.
Then, the presence of adapters (short DNA sequences ligated to the ends of DNA fragments during library preparation) is tested through the comparison of each read to a set of known adapter sequences or by using algorithms that detect adapter-like sequences and removed in a process known as “read trimming”. Finally, reads containing contaminants (genomic DNA and/or rRNA) are filtered out and the quality of filtered reads was checked again to ensure their suitability to undergo the downstream processing. 

## Alignment (or pseudoalignment) and quantification

In the RNA-seq workflow, the alignment step refers to the process of mapping sequencing reads to a reference genome or transcriptome with the goal of determining the position and orientation of each read relative to the reference sequence and allowing the subsequent gene expression quantification.

Errors, gaps or poor sequence quality regions as well as insertions/deletions (INDELs), duplicated and repetitive regions make this step challenging. Addressing these issues during the alignment step, by choosing a high-quality reference and an appropriate aligner, is essential for obtaining accurate and reliable results. A crucial component in the RNA-seq workflow is the [annotation](https://www.ncbi.nlm.nih.gov/genbank/genomes_gff) file, either in form of General Feature Format file (GFF) or in form of Gene Transfer Format file (GTF). These file formats contain key information about the location and structure of genes and transcripts and are essential for both mapping sequencing reads accurately during the alignment step and to quantify genes expression in the quantification step. Additionally, RNA-seq data often include reads that span exon-exon junctions and the annotation files provide information about splice junctions allowing the inference of different isoforms.

The aligment and quantification steps can follow two different steps according to user preferences:
- alignment and quantification;
- pseudoalignment and quantification.
In the context of RNA-seq analysis the alignmnet phase is often performed with splice-aware aligners that are utilized to take in account the splicing process. In addition to aligning reads across known splice junctions, splice-aware aligners also aim to detect novel splice junctions and alternative splicing events. Splice-aware aligners are optimized for speed and memory efficiency to handle the large volumes of RNA-seq data generated in modern sequencing experiments. They employ sophisticated algorithms and various optimization techniques, such as indexing the reference genome, parallel processing and memory-mapping, to achieve fast and scalable alignment. Popular splice-aware aligners include [STAR](https://github.com/alexdobin/STAR) and [HISAT2](https://github.com/DaehwanKimLab/hisat2). The following step is typically the quantification, which involves estimating the abundance of genes or transcripts in the samples. The workflow involves the generation of a index from the reference genome and the annotation file (GFF/GTF). This index will be used by the quantification software to map aligned reads to annotated transcripts and quantify their expression levels. The resulting expression counts or abundance estimates represent the number of reads assigned to each transcript in the samples. Several tools are available to perform the quantification step such as [featureCounts](https://subread.sourceforge.net/featureCounts.html), [HTSeq](https://htseq.readthedocs.io), [Salmon](http://combine-lab.github.io/salmon) and [RSEM](http://deweylab.github.io/RSEM).
The alignment and the quantification steps can be also performed with lightweight alignment tools, which include [Kallisto](https://pachterlab.github.io/kallisto/about.html), [Sailfish](http://www.cs.cmu.edu/~ckingsf/software/sailfish) and Salmon. These tools avoid a base-to-base alignment of reads providing quantification estimates faster than the classical splice-aware algorithms but with a high accuracy. The resulting estimates are commonly referred to as “pseudocounts” or “abundance estimates”, that can be later utilized for downstream analysis.
An example showing the differences between a reference-based aligner (STAR) and a pseudoaligner (Salmon) are represented in the scheme below:



In the sketch we can see two typical examples of alignment/pseudoalignemnt and quantification performed with two classical software, STAR and Salmon:

1) STAR seed finding process begins by searching the longest continuos portions of the reads that exactly match to one location of the reference genome (Maximal Mappable Prefix, MMP). The fragments of the reads that mapped separately are defined "seeds". If the reads comprise a splice junction (as shown in the example), the first seed will be mapped to a donor splice site. The MMP search is then applied to the unmapped portion of the read, that will be mapped to an acceptor splice site. The MMP search allows read alignment also in case of mismatches and indels, utilizing the MMP as anchor for the extension. If the extension procedure results in a poor genomic alignment (presence of library adapters or poor sequencing quality tails), the read is soft clipped. In the next step, the "anchor" alignments are selected and all the alignments located within a user-defined genomic window around the anchors are stitched together in order to find the best "linear" alignemnt. STAR assigns scores to each alignment based on various factors, including the number of mismatches, the presence of splice junctions and the overall quality alignment. The stiched combination with the highest score will result in the best alignment of a read. Through this stiching procedure also reads with a large number of mismatches, indels and gaps can be aligned. Finally, gene expression levels can be quantified with different quantification tools like the ones cited above;

2) Salmon starts by constructing a index of the transcriptome. The indexing process combines the use of a suffix array for efficient substring matching and alignment, and a hash table for rapid retrieval of transcript-specific information based on k-mer sequences. Salmon concatenates all transcripts into a single long string representing the entire transcriptome where each transcript is separated by a unique delimiter ($). Salmon generates all possible suffixes of the concatenated string and sort them lexicographically enabling efficient substring matching and search operations. 
The software also extracts all possible k-mers (fixed-length substring of nucleotides) from the transcriptome. Salmon employs a hash function to convert each k-mer sequence into a numerical hash value. The hash function maps k-mer sequences to indices within the hash table. Salmon extracts k-mers also from the read sequences and performs a lookup in the hash table for each extracted k-mer. By querying the hash table, the software retrieves the transcript position(s) within the suffix array and searches the suffix array to identify the transcript(s) that contain the k-mer sequence(s). Once Salmon identifies the candidate transcript(s) based on the matches found in the suffix array, it quantifies the abundance of each transcript. Finally the tools 


## Differential expression (DE) analysis

The next step in a typical RNA-seq workflow is the differential expression analysis. It is a statistical method to compare gene expression levels between different experimental conditions such disease vs healthy (tumor tissue vs healthy tissue), treatment vs control (sample treated with a specific stimulus, drug or compound vs untreated sample), tissue vs tissue (brain vs heart). The objective of differential expression analysis is to assess, for each gene, whether the observed differences in expression (counts) between groups are statistically significant, taking into account the variation observed within groups (replicates).
Before delving into details, it is important to point out some common characteristics of RNA-seq data that are essential to take in account in the choiche of the statistical model to utilize:

1) Low Counts and Long Right Tail: RNA-seq data often contain a large number of genes with low counts, indicating that many genes are expressed at very low levels across samples. Simultaneously, RNA-seq data exhibit a long right tail in their distribution due to the absence of an upper limit for gene expression levels. Consequently, some genes are expressed at high levels, resulting in a distribution where most genes have low to moderate expression levels, while a few genes have very high counts. This combination of many low-count genes and a few highly expressed genes presents challenges for differential expression analysis, introducing high variability and potential skewness into the data. Accurate statistical modeling must therefore account for this distribution to avoid misleading conclusions;

2) Overdispersion: RNA-seq data are characterized by overdispersion, where the variance in gene expression levels often exceeds the mean (variance > mean). In typical RNA-seq experiments, this variability is not constant and can be much higher than expected under a Poisson distribution, which assumes that the mean equals the variance (mean = variance). Overdispersion in RNA-seq data stems from biological variability, technical noise, and variations in sequencing depth across samples. Effective modeling of RNA-seq data requires statistical methods capable of handling this additional variability. The negative binomial distribution, a generalization of the Poisson distribution, addresses overdispersion by introducing an extra parameter, the dispersion parameter. This parameter allows the negative binomial distribution to capture the excess variability present in RNA-seq data, providing a more flexible and realistic representation compared to the Poisson distribution. 

To model counts data with robust statistical methods, there are different software that have been developed. This part of the analysis is typically performed in R utilizing different packages such as [DESeq2] (https://bioconductor.org/packages/release/bioc/html/DESeq2.html), [edgeR](https://bioconductor.org/packages/release/bioc/html/edgeR.html) and [limma](https://bioconductor.org/packages/release/bioc/html/limma.html). TThis tutorial focuses on DESeq2, a popular R package known for its robustness. The typical workflow is outlined in the flowchart below. For more detailed information and details refer to the [DESeq2 vignette](https://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html).

Differential expression analysis is composed by different key steps:

- Input data: the analysis starts with a matrix obtained in the alignment and quantification step that summarizes the expression levels of the different genes in each sample of the dataset. The rows of the matrix typically correspond to genes and the columns represent the samples. Each position of the matrix contains an integer value representing the number of reads associated to a particular gene in a specific sample. Another essential prerequisite is a metadata table describing the samples;

- Normalization: Since differential expression analysis tools compare counts between sample groups for the same gene, they do not need to account for gene length. However, it is crucial to account for sequencing depth and RNA composition. DESeq2 addresses these factors using size factors, which correct for variations in library sizes and RNA composition across samples. Specifically, DESeq2 calculates size factors (in general a number aroun 1) using the "median ratio" method. This involves calculating the geometric mean of each gene's counts across all samples (row-wise geometric mean), dividing each gene's count by the geometric mean, and then taking the median of these ratios for each sample (column-wise). Finally each raw count is dived by the normalization factor to generate normalized counts.
The median ratio method assumes that not all genes are differentially expressed. Large outlier genes will not disproportionately influence the median ratio values. This approach is robust to imbalances in up-/down-regulation and can handle large numbers of differentially expressed genes. By minimizing the impact of library size differences and accounting for RNA composition, this method ensures that expression levels are comparable across samples.
It is important to understand that DESeq2 does not directly use normalized counts for the actual analysis. Instead, it utilizes raw counts and incorporates the normalization process within the Generalized Linear Model (GLM). While these normalized counts are beneficial for downstream visualization of results, they should not be used as input for DESeq2 or any other differential expression analysis tools that rely on the negative binomial model;

- Quality Control: Ensuring the quality of RNA-seq data before proceeding with differential expression analysis is crucial. DESeq2 provides tools for quality control, including Principal Component Analysis (PCA) and hierarchical clustering. PCA is used to reduce the dimensionality of the data, allowing visualization of the samples in a lower-dimensional space. On the other hand, hierarchical clustering displays the correlation of gene expression for all pairwise combinations of samples in the dataset. These methods can reveal group of samples that behave similarly and can highlight potential outliers or unexpected sample patterns. For these quality control steps, DESeq2 typically uses variance-stabilized (vst) counts or regularized log-transformed (rlog) counts. These transformations stabilize the variance across the range of mean values. This means that genes with low expression and genes with high expression will have variances that are more comparable to each other after transformation. These transformed counts are used to ensure that the quality control analyses are robust and informative, aiding in the detection of any issues that could affect the downstream differential expression analysis.
Finally, prior to differential expression analysis, it is beneficial to filter out genes that are unlikely to be detected as differentially expressed. This filtering enhances the sensitivity to detect truly differentially expressed genes. These include genes with zero counts across all samples, genes with extreme count outliers, and genes with consistently low mean normalized counts across samples. DESeq2 will perform this filtering by default.